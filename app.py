import streamlit as st
import pandas as pd
import numpy as np
import io
import re

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="ç”µå•†é”€å”®æ•°æ®åˆ†æå·¥å…·", layout="wide")


# ==========================================
# 1. æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def parse_brand_rules(rules_text):
    """è§£æå“ç‰Œåˆå¹¶è§„åˆ™"""
    mapping = {}
    if not rules_text:
        return mapping
    lines = rules_text.strip().split('\n')
    for line in lines:
        if ':' in line or 'ï¼š' in line:
            parts = line.replace('ï¼š', ':').split(':')
            target = parts[0].strip()
            aliases = parts[1].split(',')
            for alias in aliases:
                clean_alias = alias.strip().lower()
                if clean_alias:
                    mapping[clean_alias] = target
    return mapping


def clean_brand_name(name, mapping):
    """æ¸…æ´—å“ç‰Œåç§°"""
    s = str(name).lower().strip()
    for alias, target in mapping.items():
        if alias in s:
            return target
    return name


def identify_price_segments(df):
    """
    æ™ºèƒ½è¯†åˆ«ä»·ä½æ®µåˆ—
    é€»è¾‘ï¼š
    1. æ’é™¤ 'å“ç‰Œ', 'brand' ç­‰éæ•°å€¼åˆ—
    2. ä¼˜å…ˆé€‰æ‹©æ•°å€¼ç±»å‹çš„åˆ—
    3. æˆ–è€…åˆ—åä¸­åŒ…å«æ•°å­—ã€æ³¢æµªå·ã€å¤§äºå°äºå·çš„åˆ—
    """
    potential_cols = []
    # æ’é™¤å¸¸è§çš„éä»·ä½æ®µåˆ—å
    exclude_names = ['å“ç‰Œ', 'brand', 'brands', 'åºå·', 'id', 'æ’å', 'rank']

    for col in df.columns:
        col_lower = str(col).lower().strip()
        if col_lower in exclude_names:
            continue

        # å¦‚æœåˆ—ååŒ…å«æ•°å­—ï¼Œæˆ–è€…æ˜¯æ•°å€¼ç±»å‹ï¼Œæˆ–è€…æ˜¯å¸¸è§çš„ä»·ä½æ®µç¬¦å·
        if (any(char.isdigit() for char in col_lower) or
                '~' in col_lower or '>' in col_lower or '<' in col_lower or
                np.issubdtype(df[col].dtype, np.number)):
            potential_cols.append(col)

    return potential_cols


def load_and_process(file_obj, coeff, mapping):
    """è¯»å–å¹¶å¤„ç†å•ä¸ªæ–‡ä»¶"""
    if file_obj is None:
        return None, None, []

    try:
        if file_obj.name.endswith('.csv'):
            df = pd.read_csv(file_obj)
        else:
            df = pd.read_excel(file_obj)
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None, None, []

    # --- 1. è‡ªåŠ¨è¯†åˆ«ä»·ä½æ®µåˆ— ---
    segments = identify_price_segments(df)

    if not segments:
        st.error(f"åœ¨æ–‡ä»¶ {file_obj.name} ä¸­æœªæ‰¾åˆ°ä»·ä½æ®µåˆ—ï¼Œè¯·æ£€æŸ¥è¡¨å¤´ã€‚")
        return None, None, []

    # --- 2. æ•°æ®æ¸…æ´—ä¸ç³»æ•°åº”ç”¨ ---
    for col in segments:
        # å¼ºåˆ¶è½¬ä¸ºæ•°å­—ï¼Œæ— æ³•è½¬æ¢çš„å˜ä¸ºNaNç„¶åå¡«0ï¼Œæœ€åä¹˜ç³»æ•°
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * coeff

    # --- 3. ä¸¥æ ¼æå–â€œå¸‚åœºæ•´ä½“â€è¡Œ ---
    # ä¸ºäº†åŒ¹é…å‡†ç¡®ï¼Œå…ˆè½¬å­—ç¬¦ä¸²å»ç©ºæ ¼
    # å°è¯•å¯»æ‰¾ 'å“ç‰Œ' åˆ—ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå°è¯•æ‰¾ç¬¬ä¸€åˆ—ä½œä¸ºå“ç‰Œåˆ—
    brand_col = 'å“ç‰Œ'
    if 'å“ç‰Œ' not in df.columns:
        # ç®€å•çš„å›é€€ç­–ç•¥ï¼šå‡è®¾ç¬¬ä¸€åˆ—æ˜¯å“ç‰Œ
        brand_col = df.columns[0]

    df['å“ç‰Œ_clean_temp'] = df[brand_col].astype(str).str.strip()

    market_row = df[df['å“ç‰Œ_clean_temp'] == 'å¸‚åœºæ•´ä½“']

    if not market_row.empty:
        market_total = market_row.iloc[0][segments]
    else:
        st.warning(f"âš ï¸ æ–‡ä»¶ `{file_obj.name}` ä¸­æœªæ‰¾åˆ° 'å¸‚åœºæ•´ä½“' è¡Œï¼ç³»ç»Ÿå°†ä½¿ç”¨ç´¯åŠ å€¼ä»£æ›¿ï¼Œæ•°æ®å¯èƒ½åå°ã€‚")
        market_total = df[segments].sum()

    # --- 4. å“ç‰Œæ¸…æ´—ä¸æ±‡æ€» ---
    # ç»Ÿä¸€ä½¿ç”¨ 'å“ç‰Œ' ä½œä¸ºåˆ—åæ–¹ä¾¿åç»­åˆå¹¶
    if brand_col != 'å“ç‰Œ':
        df = df.rename(columns={brand_col: 'å“ç‰Œ'})

    df['å“ç‰Œ'] = df['å“ç‰Œ'].apply(lambda x: clean_brand_name(x, mapping))

    # å‰”é™¤å¸‚åœºæ•´ä½“
    df_brands = df[df['å“ç‰Œ_clean_temp'] != 'å¸‚åœºæ•´ä½“'].copy()

    # æŒ‰å“ç‰Œåˆ†ç»„æ±‚å’Œ
    df_grouped = df_brands.groupby('å“ç‰Œ', as_index=False)[segments].sum()

    # æ¸…ç†ä¸´æ—¶åˆ—
    if 'å“ç‰Œ_clean_temp' in df_grouped.columns:
        del df_grouped['å“ç‰Œ_clean_temp']

    return df_grouped, market_total, segments


def generate_analysis(config, brand_mapping):
    """ç”Ÿæˆæœ€ç»ˆæŠ¥è¡¨"""
    # è·å–æ‰€æœ‰å¹´ä»½
    all_years = sorted(list(set([y for p in config.values() for y in p.keys()])))
    if not all_years:
        return None, "æœªä¸Šä¼ ä»»ä½•æ–‡ä»¶"

    year_data = {}
    valid_years = []
    # ä½¿ç”¨é›†åˆæ¥æ”¶é›†æ‰€æœ‰å‡ºç°è¿‡çš„ä»·ä½æ®µï¼Œä¿è¯ä¸æ¼
    all_seen_segments = []

    # --- ç¬¬ä¸€è½®å¾ªç¯ï¼šæ”¶é›†æ‰€æœ‰å¯èƒ½çš„ä»·ä½æ®µå¹¶ä¿æŒé¡ºåº ---
    # ä¸ºäº†ä¿æŒé¡ºåºï¼Œæˆ‘ä»¬ä¸èƒ½åªç”¨ setï¼Œå¾—ç”¨ list + æŸ¥é‡
    for platform, p_data in config.items():
        for year, item in p_data.items():
            if item['file']:
                # ç¨å¾®é¢„è¯»å–ä¸€ä¸‹åˆ—åï¼ˆä¸ºäº†æ•ˆç‡ï¼Œè¿™é‡Œå…¶å®ä¾èµ– load_and_process çš„ç»“æœæ›´ç¨³å¦¥ï¼‰
                # æ‰€ä»¥æˆ‘ä»¬åœ¨ä¸‹é¢çš„ä¸»å¾ªç¯é‡ŒåŠ¨æ€æ›´æ–° segments åˆ—è¡¨
                pass

    # --- ä¸»æ•°æ®å¤„ç†å¾ªç¯ ---
    for year in all_years:
        combined_brands = None
        combined_total = None
        has_data = False

        for platform, p_data in config.items():
            if year in p_data:
                item = p_data[year]
                file_obj = item['file']
                coeff = item['coeff']

                if file_obj:
                    # æŒ‡é’ˆå½’é›¶ï¼Œé˜²æ­¢é‡å¤è¯»å–æŠ¥é”™
                    file_obj.seek(0)
                    brands, total, segs = load_and_process(file_obj, coeff, brand_mapping)

                    if brands is not None:
                        has_data = True

                        # åŠ¨æ€æ›´æ–°å…¨å±€ä»·ä½æ®µåˆ—è¡¨ï¼ˆä¿æŒé¡ºåºï¼‰
                        for s in segs:
                            if s not in all_seen_segments:
                                all_seen_segments.append(s)

                        # å¯¹é½æ•°æ®ï¼ˆå¦‚æœä¸åŒæ–‡ä»¶ä»·ä½æ®µä¸ä¸€è‡´ï¼Œreindex ä¼šè¡¥ 0ï¼‰
                        # è¿™é‡Œæš‚ä¸ç«‹å³å¯¹é½ï¼Œåˆå¹¶æ—¶ç”± pandas outer join å¤„ç†ï¼Œæœ€åå†ç»Ÿä¸€ reindex

                        # åˆå¹¶é€»è¾‘
                        if combined_brands is None:
                            combined_brands = brands
                            combined_total = total  # Series
                        else:
                            # 1. å“ç‰Œæ•°æ®åˆå¹¶
                            combined_brands = pd.concat([combined_brands, brands], ignore_index=True)
                            # æ­¤æ—¶åˆ—å¯èƒ½å¢å¤šäº†ï¼Œfillna(0) å¾ˆé‡è¦
                            combined_brands = combined_brands.fillna(0)
                            # å†æ¬¡ group by
                            # æ³¨æ„ï¼šgroupby æ—¶è¦åŒ…æ‹¬å½“å‰æ‰€æœ‰åˆ—
                            cols_to_sum = [c for c in combined_brands.columns if c != 'å“ç‰Œ']
                            combined_brands = combined_brands.groupby('å“ç‰Œ', as_index=False)[cols_to_sum].sum()

                            # 2. å¸‚åœºæ•´ä½“æ•°æ®åˆå¹¶ (Series add Seriesï¼Œè‡ªåŠ¨å¯¹é½ç´¢å¼•)
                            combined_total = combined_total.add(total, fill_value=0)

        if has_data:
            valid_years.append(year)
            year_data[year] = {'brands': combined_brands, 'total': combined_total}

    if not valid_years:
        return None, "æ²¡æœ‰æœ‰æ•ˆæ•°æ®"

    # --- ç”Ÿæˆè¡¨æ ¼ ---
    # æœ€ç»ˆçš„è¡Œç´¢å¼•ï¼šæ‰€æœ‰å‡ºç°è¿‡çš„ä»·ä½æ®µ
    metrics = pd.DataFrame(index=all_seen_segments)

    for year in valid_years:
        y_total_series = year_data[year]['total']

        # å°† Series æ˜ å°„åˆ° DataFrameï¼Œè‡ªåŠ¨å¯¹é½ç´¢å¼•ï¼Œç¼ºå¤±å¡« 0
        metrics[f'{year}é”€é¢'] = y_total_series
        metrics[f'{year}é”€é¢'] = metrics[f'{year}é”€é¢'].fillna(0)

        grand_total = metrics[f'{year}é”€é¢'].sum()
        metrics[f'{year}å æ¯”'] = metrics[f'{year}é”€é¢'] / grand_total if grand_total else 0

    # è®¡ç®—åŒæ¯”/å˜åŒ–
    if len(valid_years) >= 2:
        y1, y2 = valid_years[-2], valid_years[-1]
        metrics['é”€é¢åŒæ¯”'] = (metrics[f'{y2}é”€é¢'] - metrics[f'{y1}é”€é¢']) / metrics[f'{y1}é”€é¢']
        metrics['å æ¯”å˜åŒ–'] = metrics[f'{y2}å æ¯”'] - metrics[f'{y1}å æ¯”']

    # è®¡ç®— TOP5
    latest_year = valid_years[-1]
    top5_list = []
    brands_df = year_data[latest_year]['brands']
    total_series = year_data[latest_year]['total']

    for seg in all_seen_segments:
        # å®‰å…¨è·å–è¯¥ä»·ä½æ®µæ€»é¢
        seg_total = total_series.get(seg, 0)

        # å®‰å…¨è·å–è¯¥ä»·ä½æ®µå“ç‰Œæ’è¡Œ
        if brands_df is not None and seg in brands_df.columns:
            top = brands_df.sort_values(by=seg, ascending=False).head(5)
            strs = []
            for _, row in top.iterrows():
                brand_sales = row[seg]
                share = brand_sales / seg_total if seg_total > 0 else 0
                strs.append(f"{row['å“ç‰Œ']}({share:.1%})")
            top5_list.append(" ".join(strs))
        else:
            top5_list.append("-")

    metrics[f'{latest_year} TOP5å“ç‰Œ(å æ¯”)'] = top5_list

    # æ ¼å¼åŒ–
    def fmt_sales(x):
        try:
            return "{:,.0f}".format(x)
        except:
            return x

    def fmt_pct(x):
        try:
            return "{:.1%}".format(x)
        except:
            return x

    def fmt_change(x):
        try:
            return "{:+.1%}".format(x)
        except:
            return x

    res = metrics.copy()
    for col in res.columns:
        if 'é”€é¢' in col and 'åŒæ¯”' not in col:
            res[col] = res[col].apply(fmt_sales)
        elif 'é”€é¢åŒæ¯”' in col:
            res[col] = res[col].apply(fmt_pct)
        elif 'å æ¯”' in col and 'å˜åŒ–' not in col and 'TOP5' not in col:
            res[col] = res[col].apply(fmt_pct)
        elif 'å æ¯”å˜åŒ–' in col:
            res[col] = res[col].apply(fmt_change)

    res = res.reset_index().rename(columns={'index': 'ä»·ä½æ®µ'})
    return res, None


# ==========================================
# 2. Streamlit ç•Œé¢å¸ƒå±€
# ==========================================

def main():
    st.title("ğŸ“Š ç”µå•†é”€å”®æ•°æ®è‡ªåŠ¨åŒ–åˆ†æå·¥å…·")

    # åˆå§‹åŒ–é…ç½®
    config = {'JD': {}, 'Tmall': {}}

    with st.sidebar:
        st.header("1. å“ç‰Œåˆå¹¶è§„åˆ™")
        default_rules = """åä¸º: åä¸ºæ™ºé€‰, é¸¿è’™\npaulmann: paulmann p\næ˜åŸº: benq, éº¦æœµå°”"""
        rules_input = st.text_area("è¾“å…¥è§„åˆ™", value=default_rules, height=150)
        brand_mapping = parse_brand_rules(rules_input)

        st.header("2. æ•°æ®ä¸Šä¼ ")
        st.info("ğŸ’¡ ç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶è¡¨å¤´ä¸­çš„ä»·ä½æ®µã€‚")

        # JD é…ç½®
        with st.expander("äº¬ä¸œ (JD)", expanded=True):
            jd24_f = st.file_uploader("JD 2024", type=['csv', 'xlsx'], key='jd24')
            jd24_c = st.number_input("JD 24ç³»æ•°", value=0.87, step=0.01, key='c_jd24')
            if jd24_f: config['JD']['2024'] = {'file': jd24_f, 'coeff': jd24_c}

            jd25_f = st.file_uploader("JD 2025", type=['csv', 'xlsx'], key='jd25')
            jd25_c = st.number_input("JD 25ç³»æ•°", value=0.87, step=0.01, key='c_jd25')
            if jd25_f: config['JD']['2025'] = {'file': jd25_f, 'coeff': jd25_c}

        # Tmall é…ç½®
        with st.expander("å¤©çŒ« (Tmall)", expanded=True):
            tm24_f = st.file_uploader("Tmall 2024", type=['csv', 'xlsx'], key='tm24')
            tm24_c = st.number_input("Tmall 24ç³»æ•°", value=0.82, step=0.01, key='c_tm24')
            if tm24_f: config['Tmall']['2024'] = {'file': tm24_f, 'coeff': tm24_c}

            tm25_f = st.file_uploader("Tmall 2025", type=['csv', 'xlsx'], key='tm25')
            tm25_c = st.number_input("Tmall 25ç³»æ•°", value=0.72, step=0.01, key='c_tm25')
            if tm25_f: config['Tmall']['2025'] = {'file': tm25_f, 'coeff': tm25_c}

    # --- è‡ªåŠ¨æ£€æµ‹æ˜¯å¦è¿è¡Œ ---
    has_file = any(config['JD']) or any(config['Tmall'])

    if not has_file:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼  Excel/CSV æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å¼€å§‹åˆ†æã€‚")
        return

    st.divider()

    # 1. æ€»ä½“åˆå¹¶è¡¨
    df_combined, err = generate_analysis(config, brand_mapping)

    if df_combined is not None:
        st.subheader("ğŸ† JD + Tmall æ¸ é“æ±‡æ€»")
        st.dataframe(df_combined, use_container_width=True)
        csv = df_combined.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ä¸‹è½½æ±‡æ€»è¡¨ (CSV)", csv, "combined_analysis.csv", "text/csv", type='primary')
    elif err:
        st.error(err)

    # 2. åˆ†å¹³å°è¡¨
    col1, col2 = st.columns(2)

    with col1:
        if any(config['JD']):
            st.subheader("ğŸ¶ äº¬ä¸œ (JD)")
            jd_conf = {'JD': config['JD']}
            df_jd, _ = generate_analysis(jd_conf, brand_mapping)
            st.dataframe(df_jd, use_container_width=True)

    with col2:
        if any(config['Tmall']):
            st.subheader("ğŸ± å¤©çŒ« (Tmall)")
            tm_conf = {'Tmall': config['Tmall']}
            df_tm, _ = generate_analysis(tm_conf, brand_mapping)
            st.dataframe(df_tm, use_container_width=True)


if __name__ == "__main__":
    main()