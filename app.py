import streamlit as st
import pandas as pd
import numpy as np
import plotly
import io


# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="ç”µå•†é”€å”®æ•°æ®åˆ†æå·¥å…·", layout="wide")


# ==========================================
# 1. æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def parse_brand_rules(rules_text):
    """
    è§£æç”¨æˆ·è¾“å…¥çš„å“ç‰Œåˆå¹¶è§„åˆ™
    æ ¼å¼: ç›®æ ‡å“ç‰Œ: åˆ«å1, åˆ«å2
    """
    mapping = {}
    if not rules_text:
        return mapping

    lines = rules_text.strip().split('\n')
    for line in lines:
        if ':' in line or 'ï¼š' in line:
            # å…¼å®¹ä¸­è‹±æ–‡å†’å·
            parts = line.replace('ï¼š', ':').split(':')
            target = parts[0].strip()
            aliases = parts[1].split(',')
            # å°†æ¯ä¸ªåˆ«åæ˜ å°„åˆ°ç›®æ ‡å“ç‰Œ
            for alias in aliases:
                clean_alias = alias.strip().lower()
                if clean_alias:
                    mapping[clean_alias] = target
    return mapping


def clean_brand_name(name, mapping):
    """æ ¹æ®æ˜ å°„è¡¨æ¸…æ´—å“ç‰Œ"""
    s = str(name).lower().strip()

    # 1. ä¼˜å…ˆåŒ¹é…ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™ (æ¨¡ç³ŠåŒ¹é…)
    for alias, target in mapping.items():
        if alias in s:
            return target

    # 2. è¿”å›åŸå
    return name


def load_and_process(file_obj, coeff, mapping):
    """
    è¯»å–å¹¶å¤„ç†å•ä¸ªæ–‡ä»¶
    é‡ç‚¹ï¼šä¸¥æ ¼æå–'å¸‚åœºæ•´ä½“'è¡Œä½œä¸ºæ€»æ•°æ®
    """
    if file_obj is None:
        return None, None, None

    try:
        if file_obj.name.endswith('.csv'):
            df = pd.read_csv(file_obj)
        else:
            df = pd.read_excel(file_obj)
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None, None, None

    # 1. è‡ªåŠ¨è¯†åˆ«æ•°å€¼åˆ—ï¼ˆä»·ä½æ®µï¼‰
    # æ’é™¤ 'å“ç‰Œ' åˆ—ï¼Œå…¶ä»–ä¸€èˆ¬ä¸ºä»·ä½æ®µ
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    # å¦‚æœæœ‰éæ•°å­—åˆ—æ··å…¥ï¼ˆæ¯”å¦‚æ–‡æœ¬æ ¼å¼çš„ä»·ä½æ®µï¼‰ï¼Œå°è¯•è½¬æ¢
    segments = []
    for col in df.columns:
        if col != 'å“ç‰Œ' and col != 'Brand':  # ç®€å•æ’é™¤
            segments.append(col)

    # 2. æ•°æ®æ¸…æ´—ä¸ç³»æ•°åº”ç”¨
    for col in segments:
        # å¼ºåˆ¶è½¬ä¸ºæ•°å­—ï¼Œæ— æ³•è½¬æ¢çš„å˜ä¸ºNaNç„¶åå¡«0ï¼Œæœ€åä¹˜ç³»æ•°
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * coeff

    # 3. ã€å…³é”®ä¿®æ”¹ã€‘ä¸¥æ ¼æå–â€œå¸‚åœºæ•´ä½“â€è¡Œ
    # å…ˆå°†å“ç‰Œåˆ—è½¬ä¸ºå­—ç¬¦ä¸²å¹¶å»ç©ºæ ¼ï¼Œé˜²æ­¢ "å¸‚åœºæ•´ä½“ " åŒ¹é…å¤±è´¥
    df['å“ç‰Œ_clean'] = df['å“ç‰Œ'].astype(str).str.strip()

    market_row = df[df['å“ç‰Œ_clean'] == 'å¸‚åœºæ•´ä½“']

    if not market_row.empty:
        # å–ç¬¬ä¸€æ¡åŒ¹é…åˆ°çš„ï¼ˆé€šå¸¸åªæœ‰ä¸€æ¡ï¼‰ï¼Œæå–æ‰€æœ‰ä»·ä½æ®µçš„æ•°æ® Series
        market_total = market_row.iloc[0][segments]
    else:
        # å¦‚æœå®åœ¨æ‰¾ä¸åˆ°ï¼Œç»™äºˆè­¦å‘Šï¼Œå¹¶æ— å¥ˆä½¿ç”¨æ±‚å’Œï¼ˆæ­¤æ—¶æ•°æ®å¯èƒ½ä¼šåå°ï¼‰
        st.warning(
            f"âš ï¸ æ–‡ä»¶ `{file_obj.name}` ä¸­æœªæ‰¾åˆ° 'å¸‚åœºæ•´ä½“' è¡Œï¼ç³»ç»Ÿå°†ä½¿ç”¨å“ç‰Œç´¯åŠ å€¼ä»£æ›¿ï¼Œæ•°æ®å¯èƒ½åå°ã€‚è¯·æ£€æŸ¥æºæ–‡ä»¶å“ç‰Œåˆ—æ˜¯å¦æœ‰ 'å¸‚åœºæ•´ä½“'ã€‚")
        market_total = df[segments].sum()

    # 4. å“ç‰Œæ¸…æ´—ä¸æ±‡æ€»ï¼ˆç”¨äºTOP5ï¼‰
    # æ¸…æ´—å“ç‰Œåç§°
    df['å“ç‰Œ'] = df['å“ç‰Œ'].apply(lambda x: clean_brand_name(x, mapping))

    # å‰”é™¤å¸‚åœºæ•´ä½“ï¼Œå¹¶æŒ‰æ¸…æ´—åçš„å“ç‰Œååˆ†ç»„æ±‚å’Œ
    df_brands = df[df['å“ç‰Œ_clean'] != 'å¸‚åœºæ•´ä½“'].copy()
    df_grouped = df_brands.groupby('å“ç‰Œ', as_index=False)[segments].sum()

    # æ¸…ç†ä¸´æ—¶åˆ—
    if 'å“ç‰Œ_clean' in df_grouped.columns:
        del df_grouped['å“ç‰Œ_clean']

    return df_grouped, market_total, segments


def generate_analysis(config, brand_mapping):
    """ç”Ÿæˆæœ€ç»ˆæŠ¥è¡¨"""
    # è·å–æ‰€æœ‰å¹´ä»½
    all_years = sorted(list(set([y for p in config.values() for y in p.keys()])))
    if not all_years:
        return None, "æœªä¸Šä¼ ä»»ä½•æ–‡ä»¶"

    # å­˜å‚¨å¤„ç†åçš„æ•°æ®
    year_data = {}
    valid_years = []
    final_segments = []

    for year in all_years:
        combined_brands = None
        combined_total = None  # è¿™æ˜¯ä¸€ä¸ªSeriesï¼Œç´¢å¼•æ˜¯ä»·ä½æ®µ
        has_data = False

        for platform, p_data in config.items():
            if year in p_data:
                item = p_data[year]
                file_obj = item['file']
                coeff = item['coeff']

                if file_obj:
                    brands, total, segs = load_and_process(file_obj, coeff, brand_mapping)
                    if brands is not None:
                        has_data = True
                        final_segments = segs  # æ›´æ–°ä»·ä½æ®µåˆ—è¡¨

                        # åˆå¹¶é€»è¾‘ï¼šå“ç‰Œæ•°æ®åˆå¹¶
                        if combined_brands is None:
                            combined_brands = brands
                            combined_total = total
                        else:
                            combined_brands = pd.concat([combined_brands, brands], ignore_index=True)
                            combined_brands = combined_brands.groupby('å“ç‰Œ', as_index=False)[segs].sum()
                            # ã€å…³é”®ã€‘æ€»æ•°æ®ç›´æ¥ç´¯åŠ ï¼ˆJDå¸‚åœºæ•´ä½“ + Tmallå¸‚åœºæ•´ä½“ï¼‰
                            combined_total = combined_total.add(total, fill_value=0)

        if has_data:
            valid_years.append(year)
            year_data[year] = {'brands': combined_brands, 'total': combined_total}

    if not valid_years:
        return None, "æ²¡æœ‰æœ‰æ•ˆæ•°æ®"

    # --- ç”Ÿæˆè¡¨æ ¼ ---
    # è¡Œç´¢å¼•ä¸ºä»·ä½æ®µ
    metrics = pd.DataFrame(index=final_segments)

    for year in valid_years:
        y_total_series = year_data[year]['total']  # è¿™æ˜¯è¯¥å¹´ä»½å„ä»·ä½æ®µçš„â€œå¸‚åœºæ•´ä½“â€ä¹‹å’Œ

        # å¡«å……åˆ°è¡¨ä¸­
        # æ³¨æ„ï¼šè¿™é‡Œè¦ç¡®ä¿ Series çš„ç´¢å¼•å’Œ metrics çš„ç´¢å¼•å¯¹é½
        # å¦‚æœæ–‡ä»¶åˆ—é¡ºåºä¸ä¸€è‡´å¯èƒ½ä¼šæœ‰é—®é¢˜ï¼Œè¿™é‡Œå‡è®¾ä¸€è‡´
        metrics[f'{year}é”€é¢'] = y_total_series

        # è®¡ç®—è¯¥å¹´çš„æ€»ç›˜å­ï¼ˆæ‰€æœ‰ä»·ä½æ®µä¹‹å’Œï¼‰
        grand_total = y_total_series.sum()
        metrics[f'{year}å æ¯”'] = metrics[f'{year}é”€é¢'] / grand_total if grand_total else 0

    # è®¡ç®—åŒæ¯”/å˜åŒ– (å¦‚æœæœ‰2å¹´ä»¥ä¸Šæ•°æ®ï¼Œå–æœ€åä¸¤å¹´)
    if len(valid_years) >= 2:
        y1, y2 = valid_years[-2], valid_years[-1]
        # é”€é¢åŒæ¯” (å¢é•¿ç‡)
        metrics['é”€é¢åŒæ¯”'] = (metrics[f'{y2}é”€é¢'] - metrics[f'{y1}é”€é¢']) / metrics[f'{y1}é”€é¢']
        # å æ¯”å˜åŒ– (ç™¾åˆ†ç‚¹å·®å€¼)
        metrics['å æ¯”å˜åŒ–'] = metrics[f'{y2}å æ¯”'] - metrics[f'{y1}å æ¯”']

    # è®¡ç®— TOP5 (å–æœ€åä¸€å¹´)
    latest_year = valid_years[-1]
    top5_list = []
    brands_df = year_data[latest_year]['brands']
    total_series = year_data[latest_year]['total']

    for seg in final_segments:
        # è¯¥ä»·ä½æ®µçš„å¸‚åœºæ€»é¢ï¼ˆæ¥è‡ªå¸‚åœºæ•´ä½“è¡Œï¼‰
        seg_total = total_series[seg] if seg in total_series else 0

        # å¯¹è¯¥ä»·ä½æ®µå“ç‰Œæ’åº
        if seg in brands_df.columns:
            top = brands_df.sort_values(by=seg, ascending=False).head(5)
            strs = []
            for _, row in top.iterrows():
                brand_sales = row[seg]
                # å æ¯” = å“ç‰Œé”€é¢ / å¸‚åœºæ•´ä½“é”€é¢
                share = brand_sales / seg_total if seg_total > 0 else 0
                strs.append(f"{row['å“ç‰Œ']}({share:.1%})")
            top5_list.append(" ".join(strs))
        else:
            top5_list.append("-")

    metrics[f'{latest_year} TOP5å“ç‰Œ(å æ¯”)'] = top5_list

    # æ ¼å¼åŒ–æ•°å­—æ˜¾ç¤º
    def fmt_sales(x):
        try:
            return "{:,.0f}".format(x)
        except:
            return x

    def fmt_pct(x):
        try:
            return "{:.1%}".format(x)
        except:
            return x

    def fmt_change(x):
        try:
            return "{:+.1%}".format(x)
        except:
            return x

    res = metrics.copy()
    for col in res.columns:
        if 'é”€é¢' in col and 'åŒæ¯”' not in col:
            res[col] = res[col].apply(fmt_sales)
        elif 'é”€é¢åŒæ¯”' in col:
            res[col] = res[col].apply(fmt_pct)
        elif 'å æ¯”' in col and 'å˜åŒ–' not in col and 'TOP5' not in col:
            res[col] = res[col].apply(fmt_pct)
        elif 'å æ¯”å˜åŒ–' in col:
            res[col] = res[col].apply(fmt_change)

    res = res.reset_index().rename(columns={'index': 'ä»·ä½æ®µ'})
    return res, None


# ==========================================
# 2. Streamlit ç•Œé¢å¸ƒå±€
# ==========================================

def main():
    st.title("ğŸ“Š ç”µå•†é”€å”®æ•°æ®è‡ªåŠ¨åŒ–åˆ†æå·¥å…·")
    st.markdown("""
    **åŠŸèƒ½è¯´æ˜ï¼š**
    1. **æ•°æ®æº**ï¼šæ”¯æŒä¸Šä¼  CSV/Excelã€‚
    2. **æ€»é”€é¢è®¡ç®—**ï¼šä¸¥æ ¼å–è‡ªæºæ–‡ä»¶ä¸­çš„ **â€œå¸‚åœºæ•´ä½“â€** è¡Œï¼Œä¹˜ä»¥ç³»æ•°åç´¯åŠ ã€‚
    3. **å“ç‰Œåˆå¹¶**ï¼šè‡ªå®šä¹‰è§„åˆ™åˆå¹¶å“ç‰Œæ•°æ®ï¼ˆä¾‹å¦‚å°†â€œåä¸ºæ™ºé€‰â€å¹¶å…¥â€œåä¸ºâ€ï¼‰ã€‚
    """)

    with st.sidebar:
        st.header("1. å“ç‰Œåˆå¹¶è§„åˆ™")
        st.info("æ ¼å¼ï¼šç›®æ ‡å“ç‰Œ: åˆ«å1, åˆ«å2 (æ¯è¡Œä¸€ä¸ª)")
        default_rules = """åä¸º: åä¸ºæ™ºé€‰, é¸¿è’™
paulmann: paulmann p
æ˜åŸº: benq, éº¦æœµå°”"""
        rules_input = st.text_area("è¾“å…¥è§„åˆ™", value=default_rules, height=150)
        brand_mapping = parse_brand_rules(rules_input)

        st.header("2. æ•°æ®ä¸Šä¼ ä¸é…ç½®")

        config = {'JD': {}, 'Tmall': {}}

        with st.expander("äº¬ä¸œ (JD) é…ç½®", expanded=True):
            st.markdown("**2024 å¹´**")
            jd24_f = st.file_uploader("JD 2024 æ–‡ä»¶", type=['csv', 'xlsx'], key='jd24')
            jd24_c = st.number_input("JD 2024 ç³»æ•°", value=0.87, step=0.01, key='c_jd24')
            if jd24_f: config['JD']['2024'] = {'file': jd24_f, 'coeff': jd24_c}

            st.markdown("---")
            st.markdown("**2025 å¹´**")
            jd25_f = st.file_uploader("JD 2025 æ–‡ä»¶", type=['csv', 'xlsx'], key='jd25')
            jd25_c = st.number_input("JD 2025 ç³»æ•°", value=0.87, step=0.01, key='c_jd25')
            if jd25_f: config['JD']['2025'] = {'file': jd25_f, 'coeff': jd25_c}

        with st.expander("å¤©çŒ« (Tmall) é…ç½®", expanded=True):
            st.markdown("**2024 å¹´**")
            tm24_f = st.file_uploader("Tmall 2024 æ–‡ä»¶", type=['csv', 'xlsx'], key='tm24')
            tm24_c = st.number_input("Tmall 2024 ç³»æ•°", value=0.82, step=0.01, key='c_tm24')
            if tm24_f: config['Tmall']['2024'] = {'file': tm24_f, 'coeff': tm24_c}

            st.markdown("---")
            st.markdown("**2025 å¹´**")
            tm25_f = st.file_uploader("Tmall 2025 æ–‡ä»¶", type=['csv', 'xlsx'], key='tm25')
            tm25_c = st.number_input("Tmall 2025 ç³»æ•°", value=0.72, step=0.01, key='c_tm25')
            if tm25_f: config['Tmall']['2025'] = {'file': tm25_f, 'coeff': tm25_c}

        run_btn = st.button("å¼€å§‹åˆ†æ", type="primary", use_container_width=True)

    if run_btn:
        if not any(config['JD']) and not any(config['Tmall']):
            st.warning("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶ï¼")
            return

        st.subheader("åˆ†æç»“æœ")

        # 1. æ€»ä½“åˆå¹¶è¡¨
        st.markdown("### ğŸ† JD + Tmall æ¸ é“æ±‡æ€»")
        df_combined, err = generate_analysis(config, brand_mapping)
        if df_combined is not None:
            st.dataframe(df_combined, use_container_width=True)
            csv = df_combined.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ä¸‹è½½æ±‡æ€»è¡¨ (CSV)", csv, "combined_analysis.csv", "text/csv")
        else:
            st.error(err)

        # 2. åˆ†å¹³å°è¡¨
        if any(config['JD']):
            st.markdown("---")
            st.markdown("### ğŸ¶ äº¬ä¸œ (JD) ç‹¬ç«‹åˆ†æ")
            jd_conf = {'JD': config['JD']}
            df_jd, _ = generate_analysis(jd_conf, brand_mapping)
            st.dataframe(df_jd, use_container_width=True)

        if any(config['Tmall']):
            st.markdown("---")
            st.markdown("### ğŸ± å¤©çŒ« (Tmall) ç‹¬ç«‹åˆ†æ")
            tm_conf = {'Tmall': config['Tmall']}
            df_tm, _ = generate_analysis(tm_conf, brand_mapping)
            st.dataframe(df_tm, use_container_width=True)


if __name__ == "__main__":
    main()